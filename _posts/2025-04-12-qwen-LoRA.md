---
layout: post
title: "从 0 到 1：我的首个 LoRA 大模型微调实战"
date: 2025-04-12 10:00:00 +0800
categories: [AI]
tags: [LoRA, Qwen, 大模型, 微调]
---

# 从 0 到 1：我的首个 LoRA 大模型微调实战

> 这是一篇记录我首次接触并实践大模型微调的博客。从一无所知到成功跑通一个 LoRA 项目，这不仅是一次技术上的突破，更是我与大模型之间的第一次对话。
>
> 想要调试模型的想法由来已久。在项目应用中，我发现通用大模型在本地化项目中不够“聪明”，行业知识难以灌输，即便使用复杂臃肿的提示词也难以达到预期效果。
>
> 最早我尝试通过云平台上的工具进行 SFT 微调，结果灵活性不足、效果不理想，于是决定自己动手，开始这次探索。

---

## 💡 为什么要了解大模型？

近年来，ChatGPT、文心一言、通义千问等大模型层出不穷，大模型正在以极快的速度重塑我们的工作方式与思维模式。

与传统模型不同，大模型不仅能完成问答、翻译、写作等任务，还具备一定的推理、总结、分析能力。通过微调（Fine-tuning），我们可以将这些能力进一步定制到业务和垂直场景中，提升效率与智能化水平。

---

## 🔍 LoRA 是什么？

LoRA（Low-Rank Adaptation）是一种参数高效微调方法：

- 引入了额外的低秩矩阵来学习新任务；
- 原始模型参数保持冻结，仅训练新增部分；
- 显著降低显存与训练时间成本，适合中小项目。

简单来说，LoRA 就像是“给模型加了一个外设外挂”，只调整它的小部分，适配新任务的同时避免对主干模型大动干戈。

![image](https://github.com/user-attachments/assets/cf2a0548-8a68-497c-9ab7-20b160f93a09)


---

## 🚀 我的微调实践简要流程

本次微调目标：基于开源模型，跑通一个完整 LoRA 微调流程，并验证调优效果。
> 初始尝试是在本地完成调试，但发现即便是 3B 级别的模型，对资源要求也远超普通 PC（例如 6G 显存的 RTX 4060）。最终妥协方案是通过降低模型体量 + 借助云平台（Google Colab）完成首次实验。

---

### 🔧 基础模型选择

- 使用模型：[Qwen1.5-1.8B-Chat](https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat)
- 原因：能力强、体量适中、支持 Chat 模式，适合初次实验。

### 📁 数据准备


- 数据格式采用类 BELLE 格式：
```json
{
  "instruction": "...任务描述...",
  "output": "...期望模型输出..."
}
```

为了保证首次调试的时候数据集的质量，我在网络上找到一些一定规模的数据集，保证了数据的质量和多样行的同时又有一定的数据，因为之前的经验自己编写了一个处理业务逻辑的数据最终在成熟的公有云上训练之后效果很差。
数据来源：
	•	公开数据集（确保质量、多样性）；
	•	避免“闭门造车”，不使用早期失败的业务自编数据；
	•	任务类型涵盖数学推理、语言转换、文本生成等。


## 🏗️  训练过程要点

在训练过程中，我完成了以下关键步骤：
	1.	使用 Hugging Face 的 transformers 加载基础模型；
	2.	利用 peft 库集成 LoRA 训练逻辑；
	3.	设置合理的 LoRA 超参数（如 rank, alpha, dropout）；
	4.	利用 Trainer 启动训练，并保存 adapter；

过程中最重要的是控制资源占用，在有限显存条件下完成训练。

## ✅ 验证效果

在多个任务上比较了以下输出：
	•	🔹 原始模型输出
	•	🔸 微调后模型输出

结果显示：
	•	在部分任务中微调模型更偏向“我的任务”，表现更好；
	•	原始模型对通用任务仍具优势；
	•	数据质量和任务设计决定了效果上限。

##📉 踩过的一些坑
	1.	过拟合风险：少量样本易导致模型过拟合，输出“刻板”。
	2.	验证集设计缺失代表性：验证不全面会误判模型能力。
	3.	训练轮数与 loss 下降不匹配：loss 降了，但输出质量不一定更好。
	4.	LoRA 参数设置对显存敏感：一不小心就 OOM，需要仔细调优。
  5.  灾难性遗忘，在不断测试的过程中，尝试不同体量不同类型的数据进行处理，产生了灾难性遗忘，原本可以回答的问题引导成了错误的答案。
  

##🌱 我的收获

通过这个项目，我不仅跑通了微调的完整流程，更获得了一些宝贵的认知：
	•	大模型微调其实没有想象中那么遥远；
	•	数据才是定制效果的关键；
	•	Prompt 与输出结构对结果有极大影响；
	•	微调≠完美，理解其边界同样重要；
